---
title: "Sleepers"
author: "Danijel Kopčinović"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sleepers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
 echo = FALSE,
 warning = FALSE,
 message = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```


# Introduction

In this vignette we will present the analysis of the survey data provided by Gradient Metrics. The data was gathered to find out the best marketing message for the mobile application that helps people with sleeping problems.

The parts of the message were organized into groups ("attributes") as follows:


```{r}

#library(sleepers)
library(haven)
library(dplyr)
library(stringr)

experiment_data = read_sav('../inst/extdata/experiment_data.sav')

# perform data adjustment, factorization, normalization...

# factorize all columns except task, duration and price
fact_columns = setdiff(colnames(experiment_data), c("task", "duration", "price"))
experiment_data[, fact_columns] = lapply(experiment_data[, fact_columns], factor)

# now factorize duration and price, but create new columns, this is just for pretty printing
experiment_data$duration_f = factor(experiment_data$duration, levels =  c("3 months", "6 months", "12 months"))
experiment_data$price_f = factor(experiment_data$price, levels = c("$20/month", "$30/month", "$40/month"))

# save factorized attributes columns names for later usage
att_columns = setdiff(colnames(experiment_data), c("response_id", "task", "duration", "price", "answer"))

# cast duration to numeric and normalize it to 0-1 range
# duration has 3 values c("3 months", "6 months", "12 months") which are not equidistant
# we want to capture this difference between the values and allow for other values too
experiment_data$duration = as.numeric(unlist(lapply(str_split(experiment_data$duration, "[[:space:]]+month(s)*"), "[[", 1)))
min_experiment_data_duration = min(experiment_data$duration)
max_experiment_data_duration = max(experiment_data$duration)
experiment_data$duration = (experiment_data$duration - min_experiment_data_duration)/(max_experiment_data_duration - min_experiment_data_duration)

# cast price to numeric and normalize it to 0-1 range
# price has 3 values c("$20/month", "$30/month", "$40/month") and these are equidistant
# we want to capture the ordering of these values and allow for other values too
experiment_data$price = as.numeric(gsub("\\$", "", unlist(lapply(str_split(experiment_data$price, "/month(s)*"), "[[", 1))))
min_experiment_data_price = min(experiment_data$price)
max_experiment_data_price = max(experiment_data$price)
experiment_data$price = (experiment_data$price - min_experiment_data_price)/(max_experiment_data_price - min_experiment_data_price)

# answer has only numbers and we want to have text descriptions
levels(experiment_data$answer) = c("Very unlikely", "Somewhat unlikely", "Somewhat likely", "Very likely")
experiment_data$answer = factor(experiment_data$answer, levels = c("Very unlikely", "Somewhat unlikely", "Somewhat likely", "Very likely"), ordered = TRUE)

# IMPORTANT: create a predict_transform function that will take new data given in the same format as 
# experiment_data and perform adjustments as described above to be able to make predictions.
predict_transform = function(new_data) {
  for (cn in setdiff(fact_columns, "answer")) {
    new_data[[cn]] = factor(new_data[[cn]], levels = levels(experiment_data[[cn]]))
  }
  if (!is.null(new_data[["answer"]])) {
    # here we assume that the answers are given as in the original data, with numbers indicating the answer
    new_data[["answer"]] = factor(new_data[["answer"]])
    levels(new_data[["answer"]]) = levels(experiment_data[["answer"]])
  }
  new_data$duration = as.numeric(unlist(lapply(str_split(new_data$duration, "[[:space:]]+month(s)*"), "[[", 1)))
  new_data$duration = (new_data$duration - min_experiment_data_duration)/(max_experiment_data_duration - min_experiment_data_duration)
  new_data$price = as.numeric(gsub("\\$", "", unlist(lapply(str_split(new_data$price, "/month(s)*"), "[[", 1))))
  new_data$price = (new_data$price - min_experiment_data_price)/(max_experiment_data_price - min_experiment_data_price)
  new_data
}

# printout attributes and values
r = lapply(att_columns, function(cn) {
  cn_levels = levels(experiment_data[[cn]])
  print(paste0("Attribute ", cn, " (", length(cn_levels), " values): ", paste(cn_levels, collapse = " | ")))
})

# just checking if every respondent answered the same number of questions > YES
# respondent_tasks = experiment_data %>% group_by(response_id) %>% summarise(max_task = max(task))
# max(respondent_tasks$max_task)-min(respondent_tasks$max_task)

```

There were `r length(levels(experiment_data$response_id))` respondents and each respondent answered `r max(experiment_data$task)` questions.

Each question had `r length(levels(experiment_data$answer))` answer options: `r paste0(levels(experiment_data$answer), collapse = " | ")`. Respondent chose one answer option on each question.

Let's have a look at how many times each attribute was shown and the frequency distribution of the answers:

```{r}

summary(experiment_data[, c(att_columns, "answer")])
# here we also see that we don't have any NAs, missing data

```

The attributes frequencies seem equally distributed. The answers frequencies tend to be "Very unlikely" but this can be simply a result of lack of buying intent by the respondents.

Since the survey data is actually a panel data (many answers from the same respondent) we will also check if there are some inconsistencies or strange behavior with respect to the respondents. Here is a summary of the buying intent answers for a few respondents:


```{r}

rank_1 = experiment_data %>% group_by(response_id) %>% 
  summarise(min_buying_intent = round(min(as.numeric(answer)), 2), 
            avg_buying_intent = round(mean(as.numeric(answer)), 2),
            max_buying_intent = round(max(as.numeric(answer)), 2),)
colnames(rank_1)[1] = "response_id"
head(rank_1, n = 10)

```


Some respondents seem to be more willing to buy, some less, but we can notice that e.g. respondent with id "R_0ezucdFLFLIYzK1" has the minimum and maximum buying intent 1. This means that all his/her answers were "Very unlikely". Such respondents pose a problem for our (later) modeling because their answers provide no information about the value of attributes, they just "pull" everything towards their single answer, in this case "Very unlikely".

Let's see how many respondents like this one we have - always giving the same answer, grouped with respect to the buying intent options:


```{r}

always_the_same_answer = rank_1$min_buying_intent == rank_1$max_buying_intent
paste0("Always the same answer: ", sum(always_the_same_answer))
paste0("All Very unlikely: ", sum(rank_1$max_buying_intent == 1))
paste0("All Somewhat unlikely: ", sum((rank_1$min_buying_intent == rank_1$max_buying_intent) & (rank_1$max_buying_intent == 2)))
paste0("All Somewhat likely: ", sum((rank_1$min_buying_intent == rank_1$max_buying_intent) & (rank_1$max_buying_intent == 3)))
paste0("All Very likely: ", sum(rank_1$min_buying_intent == 4))

```

This is quite a big number (`r round((sum(always_the_same_answer)/nrow(rank_1))*100, 2)`%) of people who constantly chose the same answer. Since the goal of this analysis is to find how the attributes affect the buying intent, we could say that for this group of respondents - **it doesn't**!

If this was not panel data we could conclude that the attributes are simply not driving enough buying intent. But since we have a panel data, we tend to conclude that the respondents who always chose the same answer either did not understand the task or simply don't care about the whole survey and didn't think about the questions at all. In both cases their answers are invalid.

That is why we will **exclude** the answers given by these people from the further analysis. This doesn't mean that these respondents shouldn't be further contacted or similar (especially those that always wanted to buy), but for the sake of this analysis their answers are invalid.

```{r}

experiment_data = experiment_data[experiment_data$response_id %in% rank_1[!always_the_same_answer, "response_id", drop = TRUE], ]

```

Besides the survey about the best marketing message for the mobile application, respondents also filled a personal survey, giving information about them, their sleeping problems, ways of coping with them etc.


```{r}

survey_data = read_sav('../inst/extdata/survey_data.sav')
# factorize all columns
survey_data_1 = data.frame(lapply(survey_data, factor))
# levels are now numeric, we want to have text descriptions on what each level means
fact_columns_names = colnames(survey_data)[colnames(survey_data) != "response_id"]
for (cn in fact_columns_names) {
  # have to make this check because some labels were NULL, unclear why
  if (!is.null(attributes(survey_data[[cn]])$labels)) {
    levels(survey_data_1[[cn]]) = names(attributes(survey_data[[cn]])$labels)
  }
}
survey_data = survey_data_1


#ftable(xtabs(~ social_proof + price_f + answer, data = experiment_data))


```


There were `r ncol(survey_data)` additional questions in this personal survey. With this additional data, we tried to segment the respondents (with respect to the answers they gave) and identify a segment/group that would be more willing to buy the mobile application.


# Experiment Data Analysis and Modelling


As a first step in our analysis of the (experimental) survey data, we will make a quick "counting" analysis: let's see what is the average "buying intent" (from 1 = `r levels(experiment_data$answer)[1]` to `r length(levels(experiment_data$answer))` = `r levels(experiment_data$answer)[length(levels(experiment_data$answer))]`) for different attributes and their values.


```{r fig.height = 4.3, fig.width = 7, fig.align = "center"}

library(ggplot2)
library(gridExtra)

cutlabelsN = function(x, N = 10) {
  is_long = nchar(x) > N
  x[is_long] = paste0(substr(x[is_long], 1, N-3), "...")
  x
}

cutlabels5 = function(x) cutlabelsN(x, 5)

plot_rvar = function(rvar, df) {
  rank_1 = df[!is.na(df[[rvar]]), ] %>% group_by(get(rvar)) %>% summarise(avg_buying_intent = round(mean(as.numeric(answer)), 2))
  colnames(rank_1)[1] = rvar
  label_fill = rep("gray", length(rank_1$avg_buying_intent))
  label_fill[rank_1$avg_buying_intent == max(rank_1$avg_buying_intent)] = "red"
  label_fill[rank_1$avg_buying_intent == min(rank_1$avg_buying_intent)] = "pink"
  ggplot(data = rank_1, aes(x = get(rvar), y = avg_buying_intent)) + scale_x_discrete(labels = cutlabelsN) + geom_col(fill = label_fill) + geom_text(aes(x = get(rvar), y = avg_buying_intent/2, label = rank_1$avg_buying_intent), data = rank_1, size = 3, colour = "white") + xlab(rvar) + theme(axis.text.x = element_text(size = 8), axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
}
ggi = lapply(att_columns, plot_rvar, df = experiment_data)
marrangeGrob(ggi, nrow = 3, ncol = 2)

```


We can see that the *price* attribute levels show relatively clear trend (higher buying intent for lower price, lower buying intent for higher price). This is expected and shows that we don't have strange behavior. 

With other attributes, we can't see such a clear trend.

Let's also have a look at the average buying intents for different 2-combinations of attribute levels:


```{r fig.height = 4.3, fig.width = 7, fig.align = "center"}

two_atts_combs = combn(x = att_columns, m = 2)
ggi2 = lapply(1:ncol(two_atts_combs), function(two_atts_i) {
  two_atts = two_atts_combs[, two_atts_i]
  fst_att = two_atts[1]
  snd_att = two_atts[2]
  #print(paste0(fst_att, ", ", snd_att))
  fst_levs = levels(experiment_data[[fst_att]])
  snd_levs = levels(experiment_data[[snd_att]])
  rank_1 = experiment_data[!is.na(experiment_data[[fst_att]]) & !is.na(experiment_data[[snd_att]]), ] %>% group_by(get(fst_att), get(snd_att)) %>% summarise(avg_buying_intent = round(mean(as.numeric(answer)), 2))
  if (nrow(rank_1) == 0) return(NULL)
  colnames(rank_1)[1:2] = c(fst_att, snd_att)
  label_fill = rep("gray", length(rank_1$avg_buying_intent))
  label_fill[rank_1$avg_buying_intent == max(rank_1$avg_buying_intent)] = "red"
  label_fill[rank_1$avg_buying_intent == min(rank_1$avg_buying_intent)] = "pink"
  ggplot(data = rank_1, aes(x = get(fst_att), y = get(snd_att))) + scale_x_discrete(labels = cutlabelsN) + scale_y_discrete(labels = cutlabelsN) + geom_label(aes(x = get(fst_att), y = get(snd_att), label = avg_buying_intent), data = rank_1, colour = "white", fill = label_fill) + xlab(fst_att)+ ylab(snd_att) + theme(axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 8))
})
ggi2 = ggi2[!sapply(ggi2, is.null)]
marrangeGrob(ggi2, nrow = 2, ncol = 2)

#grid.arrange(ggi[[1]], ggi[[2]], ggi[[3]], ggi[[4]], ggi[[5]], ggi[[6]], ggi[[7]], ggi[[8]], ggi[[9]], ncol = 2)

```


We can see that the following combinations of attributes have somewhat bigger difference between the smallest (pink) and largest (red) average buying intent: *offer + rtb, offer + price, outcome + price, rtb + price, duration + price, social_proof + price*. This indicates that some of these value combinations could have an interaction effect, where one value combined with another value gives a cumulative (positive or negative) effect on the average buying intent. Thus maybe we should include these combinations in the modeling.

It is now time to build a model. Since our output variable *answer* is an ordinal variable (has comparable values), we will use an ordinal logistic regression model with *answer* as the output variable and all other variables as predictors. 

We get the following summary:


```{r}

library(MASS)

options(contrasts = c("contr.treatment", "contr.poly"))
sleepers.plr <- polr(answer ~ duration + offer + outcome + price + rtb + social_proof, data = experiment_data, Hess = TRUE)

# save the model 
saveRDS(sleepers.plr, "sleepers.plr.RDS")

#logLik(sleepers.plr)

# all coefficients together, intercepts too, with estimate, std. error and t value
sumtable = data.frame((summary(sleepers.plr))$coefficients)
# round to 3 digits
sumtable[, colnames(sumtable)] = lapply(sumtable, round, digits = 3)
# last few coefficients are intercepts, let's emphasize that
intercepts_rows = nrow(sumtable) - ((length(sleepers.plr$zeta) - 1):0)
rownames(sumtable)[intercepts_rows] = paste0("Intercept_", rownames(sumtable)[intercepts_rows])
# now adding p-values and significance, it is a usual way to display the results, don't know why polr doesn't have it
sumtable$p.value = pt(abs(sumtable$t.value), sleepers.plr$nobs - sleepers.plr$edf, lower.tail = FALSE) * 2
sumtable$signif = ifelse(sumtable$p.value < .1, ".", "")
sumtable[sumtable$p.value < .05, ]$signif = "*"
sumtable[sumtable$p.value < .01, ]$signif = "**"
sumtable[sumtable$p.value < .001, ]$signif = "***"
sumtable$odds_effect = round(exp(sumtable$Value), 3) - 1
sumtable$explanation = "" # create a column
negative_odds_effect = (sumtable$odds_effect < 0)
sumtable[negative_odds_effect, ]$explanation = paste0("decrease buying odds by ", round(abs(sumtable[negative_odds_effect, ]$odds_effect), 3))
sumtable[!negative_odds_effect, ]$explanation = paste0("increase buying odds by ", round(sumtable[!negative_odds_effect, ]$odds_effect, 3))

# add reference levels for a clearer picture
for (an in c("offer", "outcome", "rtb", "social_proof")) {
  an_rows = grep(an, rownames(sumtable))
  sumtable = rbind(sumtable[1:(min(an_rows)-1), ], 
                   c(0, 0, 0, 1, "", 0, "reference level, effect = 0"),
                   sumtable[min(an_rows):nrow(sumtable), ]
                   )
  rownames(sumtable)[min(an_rows)] = paste0(an, levels(experiment_data[[an]])[1], ", ref. level")
}

# have to convert back to numeric, don't know why the columns were converted to character in the loop above
numeric_columns = !(colnames(sumtable) %in% c("signif", "explanation"))
sumtable[, numeric_columns] = lapply(sumtable[, numeric_columns], as.numeric)

# shorten the row names for a better presentation
rownames(sumtable) = substr(rownames(sumtable), 1, 35)

#sumtable_cis = confint(sleepers.plr)

sumtable[, c("Value", "signif", "odds_effect")]

```


Each coefficient represents attribute value (numeric or a level). Without getting into too many details about this output format, we can see (from *signif* column) that only `r paste0(rownames(sumtable[sumtable$signif != "", ]), collapse = ", ")` coefficients are significant (not 0 with high probability).

Negative coefficients in the table above mean that increasing the corresponding attribute value reduces the odds of the buying intent and vice versa - positive coefficients mean that increasing the corresponding attribute value increases the odds of the buying intent. So e.g. increasing *price* (with its negative coefficient `r sumtable["price", "Value"]`) reduces the buying intent while giving *scientific evidence* in *social_proof* (with its positive coefficient `r sumtable["social_proofscientific evidence", "Value"]`) increases the buying intent compared with the *`r levels(experiment_data$social_proof)[1]`*.

The coefficients ("Value") in the table are given on a logarithmic scale, so to find how they affect the odds of buying intent, we have to exponentiate them. This is the "odds_effect" column. If this number is < 1, the attribute value decreases the odds of buying. If this number is > 1, the attribute value increases the odds of buying.

Taking everything into account, we have the following attribute values with their effect on buying odds as just described:

```{r}

sumtable[(grepl("Interc", rownames(sumtable)) == FALSE), c("odds_effect", "explanation")]

```


Since we built an ordinal regression model, we have to check its main assumption (parallel regression assumption, a.k.a. the proportional odds assumption).


```{r message=FALSE, warning=FALSE, error=FALSE}

library(brant)
brant(sleepers.plr)

```


Looking at the probability column (it's the 3rd number in each row, some are moved to left because of an error in tabulating the output), we can see that all coefficients except price have probability of the assumption H0 above 0.05 (5%). This means that we can trust the H0 and the modeling assumption holds for these coefficients.

We ignore the Omnibus 0 probability because it's essentially a product of all the other probabilities and thus very small by default.

Price doesn't follow the proportional odds assumption, but this is expected, because influence of the price on the buying intent is not proportional, e.g. a higher price will affect the difference between *Somewhat unlikely* and *Very unlikely* less than the difference between *Very likely* and *Somewhat likely*.

Thus altogether we can proceed with the analysis.

Since a lot of coefficients are non significant, we tested if we can remove some variables from the model or improve the model by adding interactions (as explained before with the graphics).


```{r}

#addterm(sleepers.plr, ~.^2, test = "Chisq")
#sleepers.plr2 <- stepAIC(sleepers.plr, ~ . ^2)
#sleepers.plr2$anova
#anova(sleepers.plr, sleepers.plr2)

```


We found that we could remove *duration* and add the interaction *offer:outcome* but we don't get much improvement (AIC has decreased only around 5). Therefore we rather keep all the variables.


```{r}

#pr <- profile(sleepers.plr)
#confint(pr)
#plot(pr)
#pairs(pr)

```


To check how our model works on the existing data, we ran a check with the following result:


```{r}

new_data = read_sav('../inst/extdata/experiment_data.sav')
new_data = predict_transform(new_data)
# clear the same invalid respondents as previously
new_data = new_data[new_data$response_id %in% rank_1[!always_the_same_answer, "response_id", drop = TRUE], ]

# do we want to predict class = the highest probability will always win?
# note: this never gives the Very likely answer
#new_data_predicted_class = predict(sleepers.plr, new_data, type = "class")
# or do we want to take probabilities and make sample with these probabilities to determine class?
new_data_predicted_probs = predict(sleepers.plr, new_data, type = "p")
new_data_predicted_class = unlist(lapply(1:nrow(new_data_predicted_probs),function(i) sample(colnames(new_data_predicted_probs), 1, replace = TRUE, prob = new_data_predicted_probs[i, ])))
new_data_predicted_class = factor(new_data_predicted_class, levels = levels(experiment_data$answer))

library(caret)
confusionMatrix(new_data_predicted_class, new_data$answer)

```

## The best message


Summing everything up, the best marketing message would consist of:

* Duration: **12 months**
* Offer: **improve your health for the long-run**
* Outcome: **breaking bad habits and creating new routines**
* Price: **$20/month**
* Rtb: **a program created just for you** OR **cognitive behavioral therapy**
* Social proof: **scientific evidence**



# Segmentation



```{r message = FALSE, error = FALSE, warning = FALSE}

survey_data = read_sav('../inst/extdata/survey_data.sav')
# factorize all columns
survey_data_1 = data.frame(lapply(survey_data, factor))
# levels are now numeric, we want to have text descriptions on what each level means
fact_columns_names = colnames(survey_data)[colnames(survey_data) != "response_id"]
for (cn in fact_columns_names) {
  # have to make this check because some labels were NULL, unclear why
  if (!is.null(attributes(survey_data[[cn]])$labels)) {
    levels(survey_data_1[[cn]]) = names(attributes(survey_data[[cn]])$labels)
  }
}
survey_data = survey_data_1

# order survey_data by response_id
survey_data = survey_data[order(survey_data$response_id), ]

# Try to clean up NAs.

# demography
# "d_urban" "s_gender" "s_race" "d_education" "s_hhincome" "s_problem" no NAs
# "d_marital" "d_h_hnumber" "d_parent" no NAs
# "d_child_infant" "d_child_young" "d_child_older" all have 592 NAs, probably corresponding to the 592 where d_parent = No
# we can set these NAs to appropriate levels
survey_data[is.na(survey_data$d_child_infant), ]$d_child_infant = "None"
survey_data[is.na(survey_data$d_child_young), ]$d_child_young = "None"
survey_data[is.na(survey_data$d_child_older), ]$d_child_older = "None"
# "d_politics" 25 NAs, change to Other
survey_data[is.na(survey_data$d_politics), ]$d_politics = "Other"
# "d_political_view" "d_employment" 
# "d_work_schedule" "d_work_hours" both have 459 NAs, probably corresponding to d_employment = Temporarily laid off,
# Unemployed, Retired, Permanently disabled, Taking care of home or family, Student, Other (total 459)
# we will put Don’t know / not applicable for d_work_schedule
survey_data[is.na(survey_data$d_work_schedule), ]$d_work_schedule = "Don’t know / not applicable"
# we will put Less than 20 for d_work_hours
survey_data[is.na(survey_data$d_work_hours), ]$d_work_hours = "Less than 20"
# "s_region" "s_age" "weights"

# philosophy is ok, no NAs
#summary(survey_data[, grep("m1_philosophy", colnames(survey_data))])

# attitudes is ok, no NAs
#summary(survey_data[, grep("m2_attitudes", colnames(survey_data))])

# helper function, replaces NAs in factor columns defined by nameregexp
# with new level NAlevel and adds the new level to the factor levels for the columns
replaceNAandrefactor = function(nameregexp, NAlevel) {
  for (cn in grep(nameregexp, colnames(survey_data))) {
    levels(survey_data[, cn]) <<- c(levels(survey_data[, cn]), NAlevel)
    survey_data[is.na(survey_data[[cn]]), cn] <<- NAlevel
  }
}

# awareness is not ok, many NAs, probably related to the fact that people don't use/know some app
# we replace NA with None and refactor the variable
#summary(survey_data[, grep("m2_awareness", colnames(survey_data))])
# source is not OK, similar to awareness
#summary(survey_data[, grep("source", colnames(survey_data))])
# behavior_N is not OK, similar to awareness
#summary(survey_data[, grep("behavior_[[:digit:]]+", colnames(survey_data))])
replaceNAandrefactor("m2_awareness|source|behavior_[[:digit:]]+", "None")
# behavior_a_N is not OK, NAs probably mean I’m not sure
#summary(survey_data[, grep("behavior_[[:alpha:]]+", colnames(survey_data))])
replaceNAandrefactor("behavior_[[:alpha:]]+", "I’m not sure")


# order rank_1 by response_id to be able to compare with survey_data
rank_1 = rank_1[order(rank_1$response_id), ]

# check that the response_ids are equally ordered both in rank_1 and survey_data
sum(levels(rank_1$response_id)[rank_1$response_id] == levels(survey_data$response_id)[survey_data$response_id]) == nrow(rank_1)

# make simple flag variable for buyers
rank_1$buyer = ifelse(rank_1$avg_buying_intent >= 3, "buyer", "non-buyer")

buyer_levels = c("non-buyer", "buyer") # when casting to numeric, non-buyer is 0, buyer is 1

buyer_survey_data = data.frame(buyer_f = factor(rank_1$buyer, levels = buyer_levels), survey_data[, cns])
buyer_survey_data$buyer = as.numeric(buyer_survey_data$buyer_f) - 1

# remove weights because it seems numeric and it is not clear what it means
# find columns that have some correlation (chi-squared test) with the buyer flag
cns = c()
for (cn in setdiff(colnames(survey_data), c("response_id", "weights"))) {
  #print(cn)
  if (max(as.numeric(survey_data[[cn]])) > min(as.numeric(survey_data[[cn]]))) {
    cst = chisq.test(buyer_survey_data$buyer, survey_data[[cn]], simulate.p.value = TRUE)
    if (cst$p.value < 0.001) cns = c(cns, cn)
  } else {
    #print(paste0(cn, " has only one value"))
  }
}

buyer.glm <- glm(as.formula(paste0("buyer ~ ", paste(cns, collapse = " + "))), 
                 data = buyer_survey_data, 
                 family = "binomial")

library(pscl)
library(caret)
pR2(buyer.glm) # pseudo R-squared to check fit
predict_probs = predict(buyer.glm, buyer_survey_data, type = "response")
predicted_class = factor(as.numeric(predict_probs > 0.5), levels = c("0", "1"))
levels(predicted_class) = buyer_levels
confusionMatrix(data = predicted_class, reference = buyer_survey_data$buyer_f)

#coef_cis = confint(buyer.glm)

sumtable.buyer.glm = data.frame((summary(buyer.glm))$coefficients)
sumtable.buyer.glm[, colnames(sumtable.buyer.glm)] = lapply(sumtable.buyer.glm, round, digits = 3)
sumtable.buyer.glm$odds_effect = exp(sumtable.buyer.glm$Estimate)
sumtable.buyer.glm$explanation = "" # create a column
negative_odds_effect = (sumtable.buyer.glm$odds_effect < 1)
sumtable.buyer.glm[negative_odds_effect, ]$explanation = paste0("decrease buying odds by factor ", format(abs(sumtable.buyer.glm$odds_effect[negative_odds_effect]), digits = 6))
sumtable.buyer.glm[!negative_odds_effect, ]$explanation = paste0("increase buying odds by factor ", format(sumtable.buyer.glm$odds_effect[!negative_odds_effect], digits = 6))
for (an in cns) {
  an_rows = grep(an, rownames(sumtable.buyer.glm))
  sumtable.buyer.glm = rbind(sumtable.buyer.glm[1:(min(an_rows)-1), ], 
                             c(0, 0, 0, 1, 1, "reference level, no effect"),
                             sumtable.buyer.glm[min(an_rows):nrow(sumtable.buyer.glm), ]
                             )
  rownames(sumtable.buyer.glm)[min(an_rows)] = paste0(an, levels(survey_data[[an]])[1], ", ref. level")
}

# have to convert back to numeric, don't know why the columns were converted to character in the loop above
numeric_columns = !(colnames(sumtable) %in% c("signif", "explanation"))
sumtable[, numeric_columns] = lapply(sumtable[, numeric_columns], as.numeric)

# why do we need a copy?
sumtable.buyer.glm.2 = sumtable.buyer.glm
rownames(sumtable.buyer.glm) = substr(rownames(sumtable.buyer.glm), 1, 35)

# printout only a sample because there are too many coefficients
sumtable.buyer.glm[sample(1:nrow(sumtable.buyer.glm), 30, replace = FALSE), c("Estimate", "Pr...z..", "explanation")]

# find the values from the possible survey data answers that maximally increase the odds of being a buyer
best_personals = data.frame()
for (an in cns) {
  an_row_indices = grep(paste0("^", an, "[^[:digit:]]"), rownames(sumtable.buyer.glm.2))
  if (length(an_row_indices) == 0) an_row_indices = grep(paste0("^", an), rownames(sumtable.buyer.glm.2))
  an_rows = sumtable.buyer.glm.2[an_row_indices, , drop = FALSE]
  # we treat all non-significant rows, including the reference level row, as 0
  # if there is no significant row with a positive estimate, we suggest all non-significant rows
  signif_indices = an_rows$Pr...z.. < 0.1
  signif_an_rows = an_rows[signif_indices, , drop = FALSE]
  if ((nrow(signif_an_rows) > 0) && (max(signif_an_rows$Estimate) > 0)) {
    max_estimate_level = rownames(signif_an_rows)[which.max(signif_an_rows$Estimate)]
    max_estimate_level_clr = gsub(an, "", max_estimate_level)
    max_estimate_level_clr_estimate = an_rows[max_estimate_level, ]$Estimate
    max_estimate_level_clr_p_value = an_rows[max_estimate_level, "Pr...z.."]
    max_estimate_level_clr_odds_effect = an_rows[max_estimate_level, "odds_effect"]
    max_estimate_level_clr_explanation = an_rows[max_estimate_level, ]$explanation
    is_single_level = 1
    best_personals = rbind(best_personals, 
                           c(an, 
                             max_estimate_level_clr, 
                             max_estimate_level_clr_estimate, 
                             max_estimate_level_clr_p_value,
                             max_estimate_level_clr_odds_effect,
                             max_estimate_level_clr_explanation,
                             is_single_level
                             )
                           )
  } else {
    non_signif_an_rows = an_rows[!signif_indices, , drop = FALSE] # at least reference level is here
    max_estimate_level = rownames(non_signif_an_rows)
    max_estimate_level_clr = gsub(paste0(an, "|, ref. level"), "", max_estimate_level)
    is_single_level = as.numeric(length(max_estimate_level_clr) == 1)
    for (mel in max_estimate_level_clr) {
      best_personals = rbind(best_personals, 
                             c(an, 
                               mel, 
                               0, 
                               1,
                               1,
                               "no effect on buying odds",
                               is_single_level
                               )
                             )
    }
  }
}
colnames(best_personals) = c("personal", "value", "estimate", "p-value", "odds_effect", "explanation", "is_single")

# have to convert back to numeric, don't know why the columns were converted to character in the loop above
numeric_columns = c("estimate", "p-value", "odds_effect")
best_personals[, numeric_columns] = lapply(best_personals[, numeric_columns], as.numeric)

# find the best answers in the survey data to identify respondents who gave these answers
fnd_indices = lapply(unique(best_personals[best_personals$estimate != 0, ]$personal), function(cn) {
#fnd_indices = lapply(unique(best_personals$personal), function(cn) {
  which(survey_data[[cn]] %in% best_personals[best_personals$personal == cn, "value"])
})

fnd_indices_intersect = Reduce(intersect, fnd_indices)

# are these buyers?
#table(buyer_survey_data[fnd_indices_intersect, ]$buyer_f)

# printout details and the total effect on odds for the best answers
total_odds_effect = prod(best_personals[best_personals$personal > 0, ]$odds_effect)
best_personals[best_personals$estimate > 0, c("personal", "value", "odds_effect")]

```


```{r message = FALSE, error = FALSE, warning = FALSE}

maximal_k = 10

clust_survey_data = buyer_survey_data[, !(colnames(buyer_survey_data) %in% c("buyer", "buyer_f"))]
clust_survey_data[, colnames(clust_survey_data)] = lapply(clust_survey_data, as.numeric)

elbow_method(clust_survey_data, k = maximal_k, method = "kmeans")

```

```{r message = FALSE, error = FALSE, warning = FALSE}

elbow_method(clust_survey_data, k = maximal_k, method = "hclust")

```




```{r message = FALSE, error = FALSE, warning = FALSE}

### --> Define the number of clusters to be used by all algorithms
n_clusters = 3

method_return = POLCA_CLUSTERING(clust_survey_data, n_clusters)
dmodel = method_return[["dmodel"]]
dclustering = method_return[["dclustering"]]

#print(summary(dmodel))

#print(plot(dclustering))
#print_clusters(dclustering, n_clusters, clust_survey_data)
#print(paste("cluster", 1))
#print(survey_data[dclustering == 1, ]$response_id)
#print(paste("cluster", 2))
#print(survey_data[dclustering == 2, ]$response_id)

#print(paste("TOTAL WITHIN SS:", wss.total(clust_survey_data, dclustering)))

princ = prcomp(clust_survey_data)
nComp = 2
project = predict(princ, newdata = clust_survey_data)[, 1:nComp]
project.plus = cbind(as.data.frame(project),
                     cluster = as.factor(dclustering))
print(ggplot(project.plus, aes(x = PC1, y = PC2)) +
  geom_point(aes(color = cluster, shape = cluster)))

```

```{r message = FALSE, error = FALSE, warning = FALSE}

# ggplot(data = buyer_survey_data, aes(x = d_urban, fill = clustering)) + geom_bar(position = "dodge") + scale_x_discrete(labels = cutlabelsN) + xlab("d_urban")

buyer_survey_data$clustering = factor(dclustering)

table(buyer_survey_data$buyer_f, buyer_survey_data$clustering)

```

```{r message = FALSE, error = FALSE, warning = FALSE}

best_personals_single_i = (best_personals$is_single == 1)
paste0(best_personals[best_personals_single_i, ]$personal, ":", best_personals[best_personals_single_i, ]$value)

```

```{r message = FALSE, error = FALSE, warning = FALSE}

ggi = lapply(setdiff(colnames(buyer_survey_data), c("buyer", "buyer_f", "clustering")), 
#ggi = lapply(best_personals[best_personals$is_single == 1, ]$personal, 
             function(cn) {
               ggplot(data = buyer_survey_data, aes(x = get(cn), fill = clustering)) + geom_bar(position = "dodge") + scale_x_discrete(labels = cutlabels5) + xlab(cn)
             }
             )
marrangeGrob(ggi, nrow = 3, ncol = 2)

# interest_coach: "Very interested"
# past_coach: "Yes"
# interst_cbt: "Very interested"
# m1_philosophy_6: "Strongly agree"           
# m1_philosophy_2: "Strongly agree"     

```






```{r message = FALSE, error = FALSE, warning = FALSE}
### <-- AUTOMATIZATION


### --> Hierarchical Clustering

library(fpc)
cboot = clusterboot(d, clustermethod = hclustCBI, method = "ward.D", k = n_clusters)
model_hclust = cboot$result$result
# The results are in cboot$result. The output is in cboot$result$result.
summary(cboot$result)
# Groups, partition of rows
y_clust = cboot$result$partition
# Vector of cluster stabilities, each should be > 0.7.
cboot$bootmean
# How many times each cluster was dissolved (in total of 100 iterations).
cboot$bootbrd

plot(y_clust)
print_clusters(y_clust, n_clusters, d)
print(paste("TOTAL WITHIN SS:", wss.total(d, y_clust)))

# Visualising the clusters
library(cluster)
fst_index = 1
snd_index = 2
clusplot(d[, c(fst_index, snd_index)],
         y_clust,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 2,
         plotchar = FALSE,
         span = TRUE,
         main = paste('Clusters'),
         xlab = colnames(d)[fst_index],
         ylab = colnames(d)[snd_index])

library(ggplot2)
princ = prcomp(d)
nComp = 2
project = predict(princ, newdata = d)[, 1:nComp]
project.plus = cbind(as.data.frame(project),
                     cluster = as.factor(y_clust))
ggplot(project.plus, aes(x = PC1, y = PC2)) + geom_point(aes(color = cluster, shape = cluster))

### <-- Hierarchical Clustering


### --> K-means Clustering

library(fpc)
cboot = clusterboot(clust_survey_data, clustermethod = kmeansCBI, k = n_clusters)
model_kmeans = cboot$result$result
# The results are in cboot$result. The output is in cboot$result$result.
summary(cboot$result)
# Groups, partition of rows
y_clust = cboot$result$partition
# Vector of cluster stabilities, each should be > 0.7.
cboot$bootmean
# How many times each cluster was dissolved (in total of 100 iterations).
cboot$bootbrd

plot(y_clust)
print_clusters(y_clust, n_clusters, d)
print(paste("TOTAL WITHIN SS:", wss.total(d, y_clust)))

# Visualising the clusters
library(cluster)
fst_index = 3
snd_index = 4
clusplot(d[, c(fst_index, snd_index)],
         y_clust,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 2,
         plotchar = FALSE,
         span = TRUE,
         main = paste('Clusters'),
         xlab = colnames(d)[fst_index],
         ylab = colnames(d)[snd_index])

library(ggplot2)
princ = prcomp(d)
nComp = 2
project = predict(princ, newdata = d)[, 1:nComp]
project.plus = cbind(as.data.frame(project),
                     cluster = as.factor(y_clust))
ggplot(project.plus, aes(x = PC1, y = PC2)) + geom_point(aes(color = cluster, shape = cluster))

### <-- K-means Clustering


### --> MCLUST
# Uses only numeric data!

library(mclust)

df = d
for (v in colnames(d)) {
  if (is.numeric(d[[v]])) {
    df[[v]] = d[[v]]
  } else if (is.factor(d[[v]])) {
    df[[v]] = as.numeric(d[[v]])
  } else {
    # what to do with other types?
  }
}

model_mclust = Mclust(df, G = n_clusters)

#summary(model_mclust)
# Groups, partition of rows
y_clust = model_mclust$classification

plot(y_clust)
print_clusters(y_clust, n_clusters, d)
print(paste("TOTAL WITHIN SS:", wss.total(d, y_clust)))

# Visualising the clusters
library(cluster)
fst_index = 2
snd_index = 5
clusplot(d[, c(fst_index, snd_index)],
         y_clust,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 2,
         plotchar = FALSE,
         span = TRUE,
         main = paste('Clusters'),
         xlab = colnames(d)[fst_index],
         ylab = colnames(d)[snd_index])

library(ggplot2)
princ = prcomp(d)
nComp = 2
project = predict(princ, newdata = d)[, 1:nComp]
project.plus = cbind(as.data.frame(project),
                     cluster = as.factor(y_clust))
ggplot(project.plus, aes(x = PC1, y = PC2)) + geom_point(aes(color = cluster, shape = cluster))


### <-- MCLUST


### --> POLCA
# Works with only factor variables!

df = d
for (v in colnames(d)) {
  if (is.factor(d[[v]])) {
    df[[v]] = d[[v]]
  } else if (is.numeric(d[[v]])) {
    df[[v]] = factor(ifelse(d[[v]] < median(d[[v]]), 1, 2))
  } else {
    # what to do with other types?
  }
}

library(poLCA)
fff = paste(paste("cbind(", paste(colnames(df), collapse = ","), sep=""), ") ~ 1", sep = "")
model_polca = poLCA(as.formula(fff), data = df, nclass = n_clusters)

model_polca$bic
model_polca$aic

# Groups, partition of rows
y_clust = model_polca$predclass

plot(y_clust)
print_clusters(y_clust, n_clusters, d)
print(paste("TOTAL WITHIN SS:", wss.total(d, y_clust)))

# Visualising the clusters
library(cluster)
fst_index = 2
snd_index = 5
clusplot(d[, c(fst_index, snd_index)],
         y_clust,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 2,
         plotchar = FALSE,
         span = TRUE,
         main = paste('Clusters'),
         xlab = colnames(d)[fst_index],
         ylab = colnames(d)[snd_index])

library(ggplot2)
princ = prcomp(d)
nComp = 2
project = predict(princ, newdata = d)[, 1:nComp]
project.plus = cbind(as.data.frame(project),
                     cluster = as.factor(y_clust))
ggplot(project.plus, aes(x = PC1, y = PC2)) + geom_point(aes(color = cluster, shape = cluster))

### <-- POLCA


### --> Comparing clusterings

library(fpc)
cluster.stats(d, cboot$partition, model_mclust$classification)

kmeans_bic = function (fit) {
  m = ncol(fit$centers)
  n = length(fit$cluster)
  k = nrow(fit$centers)
  D = fit$tot.withinss
  return(D + log(n) * m * k)
}
print(paste(kmeans_bic(model_kmeans), model_mclust$bic))

### --> Comparing clusterings









```


Try some clustering algorithms on survey_data. What to do with NAs? If there are too many NAs, remove the column. If NAs can have a meaning, impute data.
Try to find a cluster for which the average buying intent is the highest. Hopefully this will be significantly the highest. Is there some test to see this significance?





# Discussion


It would be better if the survey was choice based instead of ratings based. E.g. we would avoid having respondents that always pick the same answer.

It would be better if we had more experiment survey data instead of really many demographic survey data (100 variables).





# Heading 1
## Heading 2
### Heading 3

--------
********

* Bulleted list
* Item 2
    * Nested bullets need a 4-space indent.
    * Item 2b
* It's possible to put multiple paragraphs of text in a list item.
    
    But to do that, the second and subsequent paragraphs must be
    indented by four or more spaces. It looks better if the first
    bullet is also indented.

1. Item 1.
    * Item a
    * Item b
1. Item 2.


Definition
  : a statement of the exact meaning of a word, especially in a dictionary.
List
  : a number of connected items or names written or printed consecutively,
typically one below the other.
  : barriers enclosing an area for a jousting tournament.

_italic_ or *italic*
__bold__ or **bold**
[link text](destination)<http://this-is-a-raw-url.com>


| Right | Left | Default | Center |
|------:|:-----|---------|:------:|
| 12    | 12   | 12      | 12     |
| 123   | 123  | 123     | 123    |
| 1     | 1    | 1       | 1      |

Notice the use of the : in the spacer under the heading. This determines the alignment of the column.


If the data underlying your table exists in R, don’t lay it out by hand. Instead, use knitr::kable(), or look at printr or pander.

To affect all blocks, call knitr::opts_chunk$set() in a knitr block:


read_sav(system.file("extdata", "experiment_data.sav", package = "sleepers"))
read_sav(system.file("extdata", "survey_data.sav", package = "sleepers"))





